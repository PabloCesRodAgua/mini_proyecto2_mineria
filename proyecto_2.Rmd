---
title: "proyecto_2_minería_de_datos"
author: "Santiago Delgado Ramos, Luis Armando Espinosa Mejía, Pablo César Rodríguez Aguayo"
date: "March 15, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## 1.- Basic Data Analysis

### 1.1.- Introduction 

### 1.2.- How data was recolected

# Limitations
# Disadvantages

### 1.3.- Basic Summary Statistics

### 1.4.- Boxplots Interpretation

### 1.5.- Skew of Data Interpretation

### 1.6.- Histograms Interpretation

### 1.7.- Quartiles Interpretation

### 1.8.- Correlation Interpretation

### 1.9.- Scatterplots Interpretation

## 2.- K - Nearest Neighbors
KNN is a supervised classified method that classifies by characteristics of unlabeled examples by assigning t
a class of similar label. The succes of this algorithm depends on the prediction, and the amount of data given.
But if the given data is noisy and there is no clear distinction among the groups, the nearest neighborg algorithms 
may struggle to identify the class boundaries.

Strenghts
- Simple and effective.
- Makes no assumptions abouthe the underlying data distribution.
- Fast training phase.
Weaknesses
- Doesn't produces a model, limiting the ability to understand how features are related to a class.
- Requieres selection of appropiate **k value**.
- Slow classification phase.
- Nominal features and missing data requiere addtional processing.



### 2.1.- Normalization
## 2.1.1 Method 1 (Min Max Normaliztion)
## 2.1.2 Method 2 ()

### 2.2.- Selected Features Explanation.

### 2.3.- Computer Distances

### 2.4.- Trainning & Testing Sets

### 2.5.- Determination of the "Optimal K"

### 2.6.- KNN Classification Outputs

### 2.7 Frequency Table & Interpretation

## 3.- Conclusions & Limitations

